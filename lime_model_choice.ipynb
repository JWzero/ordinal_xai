{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e75a81f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.800625488663018, 'adjacent_accuracy': 0.9843627834245504, 'mze': 0.19937451133698203, 'mae': 0.21579358874120408, 'mse': 0.2501954652071931, 'weighted_kappa_quadratic': 0.7844599227535709, 'weighted_kappa_linear': 0.7261909009535895, 'cem': 0.8342706258436001, 'spearman_correlation': 0.7712083357544592, 'kendall_tau': 0.7455880703163329, 'ranked_probability_score': 0.1766763479920882, 'ordinal_weighted_ce_linear': 0.549229864221745, 'ordinal_weighted_ce_quadratic': 0.7140017688787844}\n",
      "{'accuracy': 0.63125, 'adjacent_accuracy': 0.9875, 'mze': 0.36875, 'mae': 0.38125, 'mse': 0.40625, 'weighted_kappa_quadratic': 0.6287239169626759, 'weighted_kappa_linear': 0.5042791477258297, 'cem': 0.7180186382218141, 'spearman_correlation': 0.6450715185465562, 'kendall_tau': 0.6010054406985176, 'ranked_probability_score': 0.2745957430777267, 'ordinal_weighted_ce_linear': 0.7472586697604687, 'ordinal_weighted_ce_quadratic': 0.9211852209318444}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\wankm\\Projects\\ordinal_xai\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:00:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#STEP one fit good model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ordinal_xai.utils import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y = load_data(\"ordinal_xai/data/winequality-red.csv\")#,sep=\",\")#,label_map={\"unacc\":0,\"acc\":1,\"good\":2,\"vgood\":3})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from ordinal_xai.models import CLM,ONN,OBD,OGBoost\n",
    "from ordinal_xai.utils import evaluate_ordinal_model\n",
    "\n",
    "\n",
    "model = OBD(base_classifier=\"xgb\",decomposition_type=\"one-vs-following\")\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_proba_train = model.predict_proba(X_train)\n",
    "print(evaluate_ordinal_model(y_train,y_pred_train,y_pred_proba_train))\n",
    "print(evaluate_ordinal_model(y_test,y_pred,y_pred_proba))\n",
    "#refit model on full data\n",
    "model.fit(X,y)\n",
    "y_pred=model.predict(X)\n",
    "y_pred_proba=model.predict_proba(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fce9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate set of observations that is uniform distributed across ranks, generator yield\n",
    "import math\n",
    "def generate_observations(y,n=100,balance_classes=True):\n",
    "    #set random seed\n",
    "    np.random.seed(42)\n",
    "    if balance_classes == False:\n",
    "        for i in range(n):\n",
    "            yield np.random.randint(0,len(y))\n",
    "        return\n",
    "    yc = y.copy()\n",
    "    classes = np.unique(yc)\n",
    "    for i in range(n):\n",
    "        random_class = np.random.choice(classes)\n",
    "        try:\n",
    "            obs = np.random.choice(np.where(yc==random_class)[0])\n",
    "        except:\n",
    "            \"not enough samples for class\",random_class\n",
    "            return\n",
    "        #yc[obs] = -1\n",
    "        yield obs\n",
    "\n",
    "def nonzero_coefs(results):\n",
    "    if 'lower_coef' in results:\n",
    "        share_lower_nonzeroc =np.count_nonzero(results['lower_coef'])/len(results['lower_coef'])\n",
    "        if 'higher_coef' not in results:\n",
    "            return share_lower_nonzeroc\n",
    "    if 'higher_coef' in results:\n",
    "        share_higher_nonzeroc =np.count_nonzero(results['higher_coef'])/len(results['higher_coef'])\n",
    "        if 'lower_coef' not in results:\n",
    "            return share_higher_nonzeroc\n",
    "    return np.mean([share_lower_nonzeroc, share_higher_nonzeroc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e01fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree runtime:  0.15327215194702148\n",
      "L1 runtime:  4.105225563049316\n",
      "L2 runtime:  1.6071240901947021\n",
      "elastic runtime:  7.307039260864258\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from ordinal_xai.interpretation.lime import LIME\n",
    "from  time import time\n",
    "count = 0\n",
    "lime_tree_3 = LIME(model, X, y, sampling=\"uniform\", model_type=\"decision_tree\",max_samples=500)\n",
    "lime_tree_2 = LIME(model, X, y, sampling=\"uniform\", model_type=\"decision_tree\",max_depth=2,max_samples=500)\n",
    "C_values = np.logspace(-3,3,7)\n",
    "lime_L1 = {c:LIME(model, X, y, sampling=\"uniform\", model_type=\"logistic\",penalty=\"l1\",C=c,solver='liblinear',max_samples=500) for c in C_values}\n",
    "lime_L2 = {c:LIME(model, X, y, sampling=\"uniform\", model_type=\"logistic\",penalty=\"l2\",C=c,max_samples=500) for c in C_values}\n",
    "lime_elastic = {c:LIME(model, X, y, sampling=\"uniform\", model_type=\"logistic\",penalty=\"elasticnet\",C=c,solver='saga',l1_ratio=0.5,max_samples=500) for c in C_values}\n",
    "results = pd.DataFrame(columns=[\"idx\",\"true_rank\",\"predicted_rank\",\"fidelity_out_bce_tree3\",\"fidelity_out_01_tree3\",\"fidelity_out_bce_tree2\",\"fidelity_out_01_tree2\",\"fidelity_out_bce_L1\",\"fidelity_out_01_L1\",\"fidelity_out_bce_L2\",\"fidelity_out_01_L2\",\"fidelity_out_bce_elastic\",\"fidelity_out_01_elastic\",\"nonzero_coefs_L1\",\"nonzero_coefs_L2\",\"nonzero_coefs_elastic\"])\n",
    "\n",
    "for idx in generate_observations(y_pred,100,balance_classes=False):\n",
    "    #remove timing\n",
    "    count += 1\n",
    "\n",
    "    results_tree_3 = lime_tree_3.explain(observation_idx=idx)\n",
    "    fidelity_out_bce_tree3 = np.mean([results_tree_3[\"higher_fidelity_out_bce\"],results_tree_3[\"lower_fidelity_out_bce\"]])\n",
    "    fidelity_out_01_tree3 = np.mean([results_tree_3[\"higher_fidelity_out_01\"],results_tree_3[\"lower_fidelity_out_01\"]])\n",
    "    results_tree_2 = lime_tree_2.explain(observation_idx=idx)\n",
    "    fidelity_out_bce_tree2 = np.mean([results_tree_2[\"higher_fidelity_out_bce\"],results_tree_2[\"lower_fidelity_out_bce\"]])\n",
    "    fidelity_out_01_tree2 = np.mean([results_tree_2[\"higher_fidelity_out_01\"],results_tree_2[\"lower_fidelity_out_01\"]])\n",
    "    results_L1 = {c:lime_L1[c].explain(observation_idx=idx,plot=False) for c in C_values}\n",
    "    fidelity_out_bce_L1 = {c:np.mean([results_L1[c][\"higher_fidelity_out_bce\"],results_L1[c][\"lower_fidelity_out_bce\"]]) for c in C_values}\n",
    "    fidelity_out_01_L1 = {c:np.mean([results_L1[c][\"higher_fidelity_out_01\"],results_L1[c][\"lower_fidelity_out_01\"]]) for c in C_values}\n",
    "    nonzero_coefs_L1 = {c:nonzero_coefs(results_L1[c]) for c in C_values}\n",
    "    results_L2 = {c:lime_L2[c].explain(observation_idx=idx,plot=False) for c in C_values}\n",
    "    fidelity_out_bce_L2 = {c:np.mean([results_L2[c][\"higher_fidelity_out_bce\"],results_L2[c][\"lower_fidelity_out_bce\"]]) for c in C_values}\n",
    "    fidelity_out_01_L2 = {c:np.mean([results_L2[c][\"higher_fidelity_out_01\"],results_L2[c][\"lower_fidelity_out_01\"]]) for c in C_values}\n",
    "    nonzero_coefs_L2 = {c:nonzero_coefs(results_L2[c]) for c in C_values}\n",
    "    results_elastic = {c:lime_elastic[c].explain(observation_idx=idx,plot=False) for c in C_values}\n",
    "    fidelity_out_bce_elastic = {c:np.mean([results_elastic[c][\"higher_fidelity_out_bce\"],results_elastic[c][\"lower_fidelity_out_bce\"]]) for c in C_values}\n",
    "    fidelity_out_01_elastic = {c:np.mean([results_elastic[c][\"higher_fidelity_out_01\"],results_elastic[c][\"lower_fidelity_out_01\"]]) for c in C_values}\n",
    "    nonzero_coefs_elastic = {c:nonzero_coefs(results_elastic[c]) for c in C_values}\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217869f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5909090909090908"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nonzero_coefs(results):\n",
    "    if 'lower_coef' in results:\n",
    "        share_lower_nonzeroc =np.count_nonzero(results['lower_coef'])/len(results['lower_coef'])\n",
    "        if 'higher_coef' not in results:\n",
    "            return share_lower_nonzeroc\n",
    "    if 'higher_coef' in results:\n",
    "        share_higher_nonzeroc =np.count_nonzero(results['higher_coef'])/len(results['higher_coef'])\n",
    "        if 'lower_coef' not in results:\n",
    "            return share_higher_nonzeroc\n",
    "    return np.mean([share_lower_nonzeroc, share_higher_nonzeroc])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
