{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create artficial dataset with features age - numerical, height - numerical, gender - categorical (m/w/d) and predict health risk - ordinal (low, medium, high)\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "age = np.random.randint(18,100,n)\n",
    "height = np.random.randint(140,210,n)\n",
    "gender = np.random.choice([\"m\",\"w\",\"d\"],n)\n",
    "#calculate continuous health risk\n",
    "health_risk =  0.3*np.array([1 if g == \"w\" else 0 for g in gender]) + 0.05*np.random.randn(n) + 0.6*age/100 + 0.1*height/200\n",
    "#transform continuous health risk to ordinal health risk\n",
    "health_risk = pd.qcut(health_risk,3,labels=[0,1,2])\n",
    "df = pd.DataFrame({\"age\":age,\"height\":height, \"gender\":gender, \"health_risk\":health_risk})\n",
    "df.to_csv(\"data/dummy.csv\",index=False,sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.26940835,  0.37036894, -0.06415992, 10.62216765, -0.28741469,\n",
       "        1.91846704])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.CLM import CLM\n",
    "X,y = load_data(\"dummy.csv\")\n",
    "\n",
    "model = load_model(\"CLM\",link_function=\"logit\")\n",
    "\n",
    "model.fit(X,y)\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "y_prob = model.predict_proba(X)\n",
    "\n",
    "y_pred,y_prob\n",
    "\n",
    "model.params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 1, 2, 2, 0, 0, 0, 1, 0, 2, 2, 0, 1, 2, 0, 0, 2, 2, 0,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 2, 1, 0, 1, 0, 2, 2, 2, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       2, 0, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 1, 2, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 2, 2, 2,\n",
       "       1, 0, 1, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 2, 0, 2, 2, 1, 2, 2, 1, 0,\n",
       "       0, 1, 2, 0, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 2, 1,\n",
       "       0, 0, 1, 2, 1, 1, 2, 0, 0, 1, 0, 1, 1, 0, 2, 1, 0, 2, 2, 2, 2, 0,\n",
       "       0, 0, 0, 1, 2, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 2, 2, 1, 2, 2, 1, 0,\n",
       "       2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 0, 1, 0, 0, 2, 1, 0, 2, 2, 2, 1,\n",
       "       1, 2, 0, 0, 1, 2, 2, 0, 1, 0, 0, 1, 1, 0, 1, 1, 2, 2, 2, 1, 0, 1,\n",
       "       2, 1, 1, 0, 1, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 1, 0, 2, 1, 1, 2, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 1, 2, 1, 0, 0, 2, 2, 1, 0, 0, 0, 0,\n",
       "       2, 2, 1, 1, 2, 1, 1, 0, 0, 1, 2, 0, 1, 0, 2, 1, 2, 2, 2, 1, 2, 2,\n",
       "       0, 2, 1, 0, 0, 1, 1, 1, 2, 0, 0, 2, 0, 1, 2, 1, 0, 2, 0, 2, 1, 2,\n",
       "       1, 0, 2, 2, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1,\n",
       "       0, 1, 1, 2, 0, 2, 1, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 2, 1, 1, 0, 1, 0, 1, 1, 0, 0, 2, 0, 0,\n",
       "       1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 0, 2, 0, 0, 0, 1, 1, 2, 2, 0,\n",
       "       1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 0, 2, 0, 0, 2, 0, 0, 2, 2,\n",
       "       1, 1, 1, 2, 2, 0, 0, 0, 1, 2, 0, 2, 1, 0, 2, 0, 1, 2, 2, 0, 1, 1,\n",
       "       0, 2, 0, 1, 0, 2, 0, 1, 0, 1, 0, 2, 0, 2, 0, 2, 2, 0, 2, 1, 0, 1,\n",
       "       2, 0, 0, 1, 0, 1, 2, 2, 1, 0, 0, 2, 2, 0, 2, 1, 2, 2, 1, 0, 2, 0,\n",
       "       1, 2, 1, 1, 2, 2, 1, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 2, 0, 0, 1, 2,\n",
       "       0, 2, 1, 1, 2, 1, 1, 2, 0, 2, 1, 2, 1, 0, 2, 2, 1, 2, 1, 0, 2, 0,\n",
       "       2, 1, 1, 0, 1, 2, 1, 0, 2, 2, 0, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 2,\n",
       "       1, 1, 1, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 0, 1,\n",
       "       0, 2, 0, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 2, 2, 2, 2, 1, 2, 0, 0, 0, 2, 1, 2, 2, 0, 0, 2, 0, 1, 0, 2, 2,\n",
       "       0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 0, 0, 2, 2, 2, 0, 1, 0, 2, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1, 2, 0, 1, 2, 0, 2, 1, 2, 1, 1, 2,\n",
       "       0, 1, 2, 0, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0, 1, 2, 2, 1, 2, 0, 1, 2,\n",
       "       2, 0, 1, 1, 1, 2, 0, 2, 1, 0, 2, 1, 2, 1, 0, 0, 1, 2, 2, 1, 2, 0,\n",
       "       1, 1, 0, 0, 2, 0, 1, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0,\n",
       "       2, 2, 1, 1, 1, 0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 1, 2, 0, 2, 0,\n",
       "       1, 0, 2, 0, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 2, 0, 1, 0, 0, 2, 2, 0, 2, 1, 1, 2, 1, 1, 0, 0, 2, 0, 0, 0, 1,\n",
       "       2, 1, 2, 0, 2, 2, 2, 1, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 1, 0, 2,\n",
       "       1, 2, 0, 0, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 2, 2, 0, 0, 2, 0, 0, 1,\n",
       "       1, 0, 2, 1, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 1, 1, 2, 0, 0,\n",
       "       0, 2, 0, 2, 1, 0, 0, 0, 1, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1, 2,\n",
       "       0, 0, 0, 0, 2, 0, 0, 1, 2, 2, 0, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 2, 1, 2, 2, 0, 0, 2, 0, 0, 1, 0, 1, 0, 1, 2, 0, 1,\n",
       "       2, 0, 1, 1, 0, 0, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create simple test data\n",
    "y_true = np.array([0, 1, 2, 1, 0])\n",
    "y_perfect_pred_proba = np.array([\n",
    "    [1.0, 0.0, 0.0],  # Class 0\n",
    "    [0.0, 1.0, 0.0],  # Class 1\n",
    "    [0.0, 0.0, 1.0],  # Class 2\n",
    "    [0.0, 1.0, 0.0],  # Class 1\n",
    "    [1.0, 0.0, 0.0]   # Class 0\n",
    "])\n",
    "y_perfect_pred = y_perfect_pred_proba.argmax(axis=1)\n",
    "y_worst_pred_proba = np.array([\n",
    "    [0.0, 0.0, 1.0],  # Class 2\n",
    "    [1.0, 0.0, 0.0],  # Class 0\n",
    "    [1.0, 0.0, 0.0],  # Class 0\n",
    "    [0.0, 0.0, 1.0],  # Class 2\n",
    "    [0.0, 0.0, 1.0]   # Class 2\n",
    "])\n",
    "y_worst_pred = y_worst_pred_proba.argmax(axis=1)\n",
    "y_uncertain_pred_proba = np.array([\n",
    "    [0.5, 0.3, 0.2],  # Class 0\n",
    "    [0.2, 0.5, 0.3],  # Class 1\n",
    "    [0.1, 0.2, 0.7],  # Class 2\n",
    "    [0.3, 0.4, 0.3],  # Class 1\n",
    "    [0.8, 0.1, 0.1]   # Class 0\n",
    "])\n",
    "y_uncertain_pred = y_uncertain_pred_proba.argmax(axis=1)\n",
    "y_one_error_pred_proba = np.array([\n",
    "    [1.0, 0.0, 0.0],  # Class 0\n",
    "    [0.0, 1.0, 0.0],  # Class 1\n",
    "    [0.0, 0.0, 1.0],  # Class 2\n",
    "    [0.0, 1.0, 0.0],  # Class 1\n",
    "    [0.0, 0.0, 1.0]   # Class 0\n",
    "])\n",
    "y_one_error_pred = y_one_error_pred_proba.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X_inf_0   X_inf_1   X_inf_2   X_inf_3   X_inf_4  X_inter_0  X_inter_1  \\\n",
      "0  0.496714  1.399355 -0.675178 -1.907808 -0.863494  -0.423760  -1.114081   \n",
      "1 -0.138264  0.924634 -0.144519 -0.860385 -0.031203  -0.453414  -0.630931   \n",
      "2  0.647689  0.059630 -0.792420 -0.413606  0.018017  -1.795643  -0.942060   \n",
      "3  1.523030 -0.646937 -0.307962  1.887688  0.472630  -0.330090  -0.547996   \n",
      "4 -0.234153  0.698223 -1.893615  0.556553 -1.366858   0.732829  -0.214150   \n",
      "\n",
      "   X_border_0  X_border_1  X_border_2  ...  X_noise_13  X_noise_14  \\\n",
      "0    0.785185   -0.033025    0.765402  ...    2.198837   -0.671374   \n",
      "1   -1.777681   -0.503650    1.073413  ...    0.343355   -0.713799   \n",
      "2    0.714746   -0.172375    0.498690  ...   -0.233590    1.425406   \n",
      "3   -0.233724    0.714732   -1.942498  ...    0.976983    1.864414   \n",
      "4    0.707458    1.277857   -0.155422  ...    0.842069   -0.928882   \n",
      "\n",
      "   X_noise_15  X_noise_16  X_noise_17  X_noise_18  X_noise_19  X_corr0_strong  \\\n",
      "0    0.170874   -0.141343   -0.783760    1.765593    0.594798        0.384968   \n",
      "1    0.012255   -1.182520    1.164034    0.680551    0.553490       -0.216281   \n",
      "2   -0.431155   -0.119706    0.782878    0.674299    3.354573        0.610323   \n",
      "3   -0.002527    0.147996   -0.021273   -0.897427   -1.077131        1.541946   \n",
      "4    0.490842    0.518835    0.144337    1.769062   -0.625985       -0.208041   \n",
      "\n",
      "   X_corr1_weak  y  \n",
      "0     -0.575011  2  \n",
      "1      1.236640  0  \n",
      "2     -0.949558  4  \n",
      "3      0.613524  1  \n",
      "4      0.312742  0  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate features\n",
    "# 5 standard informative features\n",
    "informative_features = {\n",
    "    f'X_inf_{i}': np.random.normal(0, 1, n_samples) for i in range(5)\n",
    "}\n",
    "\n",
    "# 2 interaction-only informative features\n",
    "interaction_features = {\n",
    "    f'X_inter_{i}': np.random.normal(0, 1, n_samples) for i in range(2)\n",
    "}\n",
    "interaction_term = interaction_features['X_inter_0'] * interaction_features['X_inter_1']\n",
    "\n",
    "# 3 features that only affect specific rank borders\n",
    "border_features = {\n",
    "    f'X_border_{i}': np.random.normal(0, 1, n_samples) for i in range(3)\n",
    "}\n",
    "\n",
    "# 20 noise features (now normally distributed)\n",
    "noise_features = {\n",
    "    f'X_noise_{i}': np.random.normal(0, 1, n_samples) for i in range(20)\n",
    "}\n",
    "\n",
    "# Correlated features\n",
    "# Very strong correlation with X_inf_0\n",
    "X_corr_strong = informative_features['X_inf_0'] + np.random.normal(0, 0.05, n_samples)\n",
    "X_corr_strong = (X_corr_strong - np.mean(X_corr_strong)) / np.std(X_corr_strong)\n",
    "\n",
    "# Very weak correlation with X_inf_1\n",
    "X_corr_weak = informative_features['X_inf_1'] + np.random.normal(0, 2.0, n_samples)\n",
    "X_corr_weak = (X_corr_weak - np.mean(X_corr_weak)) / np.std(X_corr_weak)\n",
    "\n",
    "# Latent variable with standard linear informative features\n",
    "latent = (2.0 * informative_features['X_inf_0']\n",
    "          - 1.5 * informative_features['X_inf_1']\n",
    "          + 1.2 * informative_features['X_inf_2']\n",
    "          - 0.7 * informative_features['X_inf_3']\n",
    "          + 0.5 * informative_features['X_inf_4']\n",
    "          + np.random.normal(0, 0.7, n_samples))\n",
    "\n",
    "# Add interaction term effect across all samples\n",
    "latent += 2.0 * interaction_term\n",
    "\n",
    "# Add border-specific effects\n",
    "latent_adjusted = latent.copy()\n",
    "latent_adjusted[(latent > -1.5) & (latent <= 0)] += 1.5 * border_features['X_border_0'][(latent > -1.5) & (latent <= 0)]\n",
    "latent_adjusted[(latent > 0) & (latent <= 1.5)] += 1.5 * border_features['X_border_1'][(latent > 0) & (latent <= 1.5)]\n",
    "latent_adjusted[(latent > 1.5) & (latent <= 3)] += 1.5 * border_features['X_border_2'][(latent > 1.5) & (latent <= 3)]\n",
    "\n",
    "# Define thresholds for 5 classes\n",
    "thresholds = [-np.inf, -1.5, 0, 1.5, 3, np.inf]\n",
    "\n",
    "# Assign ordinal categories\n",
    "y = np.digitize(latent_adjusted, thresholds) - 1\n",
    "\n",
    "# Combine all features into a DataFrame\n",
    "data = pd.DataFrame({**informative_features, **interaction_features, **border_features, **noise_features})\n",
    "data['X_corr0_strong'] = X_corr_strong\n",
    "data['X_corr1_weak'] = X_corr_weak\n",
    "data['y'] = y\n",
    "\n",
    "# Save to CSV\n",
    "data.to_csv('data/FI_test.csv', index=False, sep=';')\n",
    "\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X_0       X_1       X_2       X_3       X_4  y\n",
      "0 -0.293152  1.576923 -1.555651  1.577035 -0.016757  0\n",
      "1 -0.997532  0.338188 -0.004144  0.596183  0.432148  0\n",
      "2  0.895271 -1.404910 -0.332971 -1.580417  0.383399  4\n",
      "3 -0.391267  0.712897 -1.862389 -0.768348 -2.383953  1\n",
      "4 -0.726363  0.009363 -0.447901  1.020788  0.188182  0\n"
     ]
    }
   ],
   "source": [
    "#simple version\n",
    "n_samples=1000\n",
    "# Generate features\n",
    "# 5 standard normal features\n",
    "features = {\n",
    "    f'X_{i}': np.random.normal(0, 1, n_samples) for i in range(5)\n",
    "}\n",
    "\n",
    "latent = 3 * features[\"X_0\"] - 2 * features[\"X_1\"] - features[\"X_2\"] + np.random.normal(0,1,n_samples) # 4 and 5 are noise\n",
    "# Define thresholds for 5 classes\n",
    "thresholds = [-np.inf, -1.5, 0, 1.5, 3, np.inf] \n",
    "\n",
    "# Assign ordinal categories\n",
    "y = np.digitize(latent, thresholds) - 1\n",
    "\n",
    "data = pd.DataFrame({**features})\n",
    "data[\"y\"] = y\n",
    "# Save to CSV\n",
    "data.to_csv('data/FI_simple.csv', index=False, sep=';')\n",
    "\n",
    "print(data.head()) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
